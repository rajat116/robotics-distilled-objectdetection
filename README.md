# **Robotics Object Detection with YOLOv8 Knowledge Distillation + End-to-End MLOps on AWS**

This project demonstrates a **production-grade machine learning system** for deploying, monitoring, and retraining an edge-ready **object detection model** for robotics applications.

Robotics hardware imposes strict constraints:

* âœ” **low latency**
* âœ” **small model size**
* âœ” **consistent tail-latency (p95)**
* âœ” **high detection accuracy**
* âœ” **ability to adapt to drift over time**

To address this, we build a **full MLOps pipeline** that:

* Trains a **YOLOv8s teacher** and a lightweight **YOLOv8n student**
* Applies **label-based knowledge distillation** to create a much stronger **YOLOv8n-KD student**
* Benchmarks latency, accuracy, and robustness
* Deploys via **FastAPI + Docker**
* Uses **MLflow Model Registry** (running on AWS EC2 + S3)
* Automates retraining & promotion via **Airflow**
* Monitors data drift with a dedicated **Drift Detection DAG**
* Provides model comparison plots, inference visualizations, and performance summaries

This repository showcases **all components of the ML lifecycle**â€”training â†’ registry â†’ inference â†’ monitoring â†’ retraining â†’ redeployment.

---

# ğŸ” **1. Problem Motivation**

Modern robotic systems (autonomous mobile robots, UAVs, warehouse bots) rely heavily on **real-time object detection**.
However:

* High-capacity models (YOLOv8s, YOLOv8m) are accurate but **too slow/heavy** for embedded devices
* Tiny models (YOLOv8n) are fast but **lose significant accuracy**
* The model must run **24/7 on hardware**, meaning:

  * strict **latency budgets**
  * **limited compute and memory**
  * **high reliability**
  * **resistance to data drift**

Therefore, we need a model that is:

* **small**
* **fast**
* **accurate**
* **maintainable in production**
* **automatically retrained when drift occurs**

---

# ğŸ§  **2. Solution: Knowledge Distillation + Full MLOps Pipeline**

We implement **label-based knowledge distillation (KD)**:

* The **teacher** (YOLOv8s) generates high-quality pseudo-labels
* The **student** (YOLOv8n) trains on those labels
* The distilled student becomes **much more accurate** while remaining **lightweight and fast**

Then we integrate this training process into a **complete MLOps system**:

### âœ” Training on AWS EC2 with MLflow logging

### âœ” Model Registry with versioning (Staging â†’ Production)

### âœ” Retraining DAG triggered by Airflow

### âœ” Drift Detection DAG to monitor incoming data

### âœ” CI/CD with GitHub Actions

### âœ” Dockerized inference (FastAPI)

### âœ” Benchmarking suite

### âœ” Automated model promotion and rollback logic

This is the same workflow used in professional robotics, autonomous driving, and real-time AI systems.

---

# ğŸ§© **3. Architecture Overview**

## **High-Level Pipeline**

```
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚   Raw Dataset      â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â–¼
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚   Teacher Model     â”‚ (YOLOv8s)
                  â”‚ GT + Predictions    â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â–¼
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚  KD Label Generator â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Student (YOLOv8n)    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
        â”‚ KD-Student (YOLOv8n-KD) â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â–¼
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚ MLflow Tracking     â”‚
                  â”‚ & Model Registry    â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â–¼
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚ Airflow Retrain Pipeline     â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Production Model (Latest KD)  â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚ FastAPI + Docker Inference Service     â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# ğŸ“ **4. Repository Structure**

```
src/
â”‚
â”œâ”€â”€ training/                 # Teacher, student, KD training scripts
â”œâ”€â”€ distillation/             # Generates KD supervision labels
â”œâ”€â”€ inference/                # FastAPI inference service
â”œâ”€â”€ monitoring/               # Drift detection + Prometheus metrics
â”œâ”€â”€ evaluation/               # Metrics comparison & benchmarking
â”œâ”€â”€ benchmarking/             # Latency/perf testing
â””â”€â”€ utils/                    # Config + logging helpers

airflow_docker/
â”‚   â”œâ”€â”€ dags/                 # Retraining DAG + Drift DAG
â”‚   â”œâ”€â”€ Dockerfile.worker
â”‚   â”œâ”€â”€ docker-compose.yaml
â”‚   â””â”€â”€ keys/                 # SSH keys for EC2
```

Models:

```
models/
â”œâ”€â”€ teacher/
â”œâ”€â”€ student/
â””â”€â”€ student_kd/
```

Figures (inference visuals + charts):

```
figures/
â”œâ”€â”€ input_image.jpg
â”œâ”€â”€ detection_teacher.jpg
â”œâ”€â”€ detection_student.jpg
â””â”€â”€ detection_student_kd.jpg
```

---

# ğŸ–¼ï¸ **5. Inference Visualizations**

These are automatically generated using:

```
python scripts/generate_inference_images.py
```

### **Input Image**

<img src="figures/input_image.jpg" width="260" height="350"/>

### **Teacher Detection**

![teacher detection](figures/detection_teacher.jpg)

### **Student Detection**

![student detection](figures/detection_student.jpg)

### **Distilled Student Detection**

![student kd](figures/detection_student_kd.jpg)

---

# ğŸ“Š **6. Performance Comparison**

## âœ” Key Detection Metrics (from YOLO results.csv)

Insert the table as:

```
| metric                 | teacher | student | student_KD |
|------------------------|---------|---------|------------|
| mAP50                  | 0.640   | 0.520   | â­ 0.760   |
| mAP50â€“95               | 0.488   | 0.387   | â­ 0.619   |
| precision              | 0.653   | 0.592   |    0.643   |
| recall                 | 0.605   | 0.503   | â­ 0.712   |
```

### âœ” Interpretation

* KD student achieves **~46% improvement in mAP50** over the baseline
* KD student surpasses even the teacher in overall mAP on COCO128
* Recall improves significantly â†’ fewer missed detections
* Precision remains similar â†’ quality maintained

---

# âš¡ **7. Model Sizes & Latency**

## **Size Comparison**

```
| model       | size    | notes                   |
|-------------|---------|-------------------------|
| teacher     | 21.5 MB | YOLOv8s heavy model     |
| student     | 6.2 MB  | YOLOv8n fast baseline   |
| student_kd  | 6.2 MB  | Same size as student    |
```

## **Average Latency**

```
| model       | avg latency | speedup vs teacher|
|-------------|-------------|-------------------|
| teacher     | 84 ms       | baseline          |
| student     | 34 ms       | ~2.4Ã— faster      |
| student_kd  | 46 ms       | ~1.8Ã— faster      |
```

## **p95 Worst-Case Latency**

```
| model       | p95 latency | interpretation              |
|-------------|-------------|-----------------------------|
| teacher     | 103 ms      | slow heavy model            |
| student     | 52 ms       | stable & consistent         |
| student_kd  | 91 ms       | slight KD overhead          |
```

---

# ğŸ§ª **8. Full MLOps Pipeline Components**

## âœ” **Training on EC2**

All training scripts log:

* hyperparameters
* losses
* mAP metrics
* weight artifacts
* confusion matrices

into MLflow (running on EC2 + S3).

---

## âœ” **MLflow Model Registry**

Models stored as:

* `yolo-teacher`
* `yolo-student`
* `yolo-student-kd`

Stages:

* Staging
* Production

Promotion automated via Airflow.

---

## âœ” **Airflow Retraining Pipeline**

DAG executes:

1. Check for new data
2. Train teacher
3. Train student
4. Train KD student
5. Register models in MLflow
6. Compare mAP50â€“95
7. Promote best model â†’ Production
8. Notification

---

## âœ” **Drift Detection Pipeline**

* Runs on EC2
* Computes pixel-level drift
* Saves JSON reports under `reports/drift/`
* Airflow pulls drift results via SCP
* If drift_score > threshold â†’ triggers retraining DAG

This simulates a real production system where environments drift over time.

---

## âœ” **Inference Service (FastAPI + Docker)**

Endpoints:

```
/health
/predict
/metrics  (Prometheus format)
```

Supports shadow deployments:

* primary = production model
* shadow = next candidate model

Allows online A/B evaluation.

---

## âœ” **CI/CD with GitHub Actions**

CI runs:

* Black
* Flake8
* Pytest
* Builds inference Docker image
* Ensures code quality + reproducibility

---

# âš™ï¸ **9. How to Run the Project**

---

## **A. Local Inference**

```
docker build -t yolo-inference -f Dockerfile.inference .
docker run -p 8000:8000 yolo-inference
```

Open:

```
http://localhost:8000/docs
```

Upload an image â†’ get detections.

---

## **B. Airflow (in Codespace)**

```
cd airflow_docker
docker compose up -d
```

Open UI:

```
http://localhost:8080
```

---

## **C. Training on EC2**

SSH:

```
ssh -i yolo-robotics.pem ubuntu@<EC2-IP>
```

Run training:

```
python -m src.training.train_teacher
```

---

## **D. Drift Job Manual Run**

```
python src/monitoring/drift_job.py
```

---

# ğŸ **10. Conclusion**

This repository demonstrates a **complete, production-grade MLOps system**, built around a robotics-ready object detection pipeline:

* âœ” Lightweight + accurate model via knowledge distillation
* âœ” MLflow model registry for lifecycle management
* âœ” Airflow for orchestration & automated retraining
* âœ” Drift detection pipeline
* âœ” FastAPI inference with metrics
* âœ” CI/CD & containerized deployment
* âœ” Benchmarking + performance analysis

It represents a **real-world MLOps design**, suitable for robotics, IoT, autonomous systems, and any latency-critical ML application.

---
